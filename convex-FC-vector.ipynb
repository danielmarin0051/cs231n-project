{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd09577b925a68854775df3f8f47c8cb48d58c3aba35c875d15bb2fa55a13640e45",
   "display_name": "Python 3.8.8 64-bit ('cs231n': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you are using Colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/cs231n-project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cvxpy as cp\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.utils import relative_error\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_TRAIN = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset FashionMNIST\n    Number of datapoints: 60000\n    Root location: data\n    Split: Train\n    StandardTransform\nTransform: ToTensor()\nDataset FashionMNIST\n    Number of datapoints: 10000\n    Root location: data\n    Split: Test\n    StandardTransform\nTransform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "# number of datapoints: 60,000\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "\n",
    "loader_train = DataLoader(train_data, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "val_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "\n",
    "loader_val = DataLoader(val_data, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 60000)))\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train\n(50000, 28, 28)\n(50000,)\nVal\n(10000, 28, 28)\n(10000,)\nTest\n(10000, 28, 28)\n(10000,)\nDev\n(30, 28, 28)\n(30,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.data.numpy()\n",
    "y_train = train_data.targets.numpy()\n",
    "X_test = test_data.data.numpy()\n",
    "y_test = test_data.targets.numpy()\n",
    "\n",
    "X_val = X_train[-10000:,:,:]\n",
    "y_val = y_train[-10000:]\n",
    "X_train = X_train[:-10000,:,:]\n",
    "y_train = y_train[:-10000]\n",
    "X_dev = X_train[:30,:,:]\n",
    "y_dev = y_train[:30]\n",
    "print('Train')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Val')\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print('Test')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print('Dev')\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    return X.reshape((X.shape[0], -1))\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model_fn):\n",
    "    \"\"\"\n",
    "    Check the accuracy of a classification model.\n",
    "    \n",
    "    Inputs:\n",
    "    - loader: A DataLoader for the data split we want to check\n",
    "    - model_fn: A function that performs the forward pass of the model,\n",
    "      with the signature scores = model_fn(x, params)\n",
    "    - params: List of PyTorch Tensors giving parameters of the model\n",
    "    \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    split = 'val' if loader.dataset.train else 'test'\n",
    "    print('Checking accuracy on the %s set' % split)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "            # scores = model_fn(x, params)\n",
    "            scores = model_fn(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "def train(model, optimizer, epochs):\n",
    "    model = model.to(device=device)\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()\n",
    "            x = x.to(device=device)  \n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 100 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy(loader_val, model)\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(28*28, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 10),\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    momentum=0.9,\n",
    "    nesterov=True,\n",
    ")\n",
    "\n",
    "# train(model, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make plot of training accuracy vs time\n",
    "# TODO: Constrain first layer weights to have unit normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Y.shape = (50000, 10)\n",
      "########\n",
      "Started Convex FC Vector Solver...\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                    v1.1.12                                    \n",
      "===============================================================================\n",
      "(CVXPY) May 11 12:19:38 PM: Your problem has 12808820 variables, 500040 constraints, and 0 parameters.\n",
      "(CVXPY) May 11 12:25:27 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) May 11 12:25:27 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) May 11 12:25:27 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 11 12:32:45 PM: Compiling problem (target solver=SCS).\n",
      "(CVXPY) May 11 12:32:45 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCS\n",
      "(CVXPY) May 11 12:32:45 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) May 11 12:41:13 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) May 11 12:49:23 PM: Applying reduction ConeMatrixStuffing\n"
     ]
    }
   ],
   "source": [
    "from lib.convex_fc_vector import Convex_FC_Vector_Solver\n",
    "solver = Convex_FC_Vector_Solver()\n",
    "Z, Z_prime, loss = solver.solve(flatten(X_train), y_train, num_classes=10, beta=0.1, max_iters=50000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "Y_hat = solver.predict(flatten(X_train), Z, Z_prime)\n",
    "y_pred = np.argmax(Y_hat, axis=1)\n",
    "\n",
    "train_accuracy = np.sum(y_train == y_pred) / y_train.shape[0]\n",
    "print(f'train_accuracy: {train_accuracy}')"
   ]
  }
 ]
}